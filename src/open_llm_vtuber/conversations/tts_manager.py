import asyncio
import json
import re
import uuid
from datetime import datetime
from typing import List, Optional, Dict, Tuple
from loguru import logger

from ..agent.output_types import DisplayText, Actions
from ..live2d_model import Live2dModel
from ..tts.tts_interface import TTSInterface
from ..utils.stream_audio import prepare_audio_payload, get_audio_duration
from ..config_manager.utils import get_lingxi_settings
from .types import WebSocketSend


class TTSTaskManager:
    """Manages TTS tasks and ensures ordered delivery to frontend while allowing parallel TTS generation"""

    def __init__(self) -> None:
        self.task_list: List[asyncio.Task] = []
        self._lock = asyncio.Lock()
        # Queue to store ordered payloads
        self._payload_queue: asyncio.Queue[Dict] = asyncio.Queue()
        # Task to handle sending payloads in order
        self._sender_task: Optional[asyncio.Task] = None
        # Counter for maintaining order
        self._sequence_counter = 0
        self._next_sequence_to_send = 0
        
        # éŸ³é¢‘åˆå¹¶ç¼“å†²åŒºï¼ˆä»…ç”¨äº Step TTSï¼‰
        # å­˜å‚¨å…ƒç»„: (tts_text, display_text, actions)
        # æ³¨æ„ï¼šåªæœ‰é€šè¿‡æ ‡é¢˜è¿‡æ»¤çš„æœ‰æ•ˆ TTS æ–‡æœ¬æ‰ä¼šè¿›å…¥ç¼“å†²åŒº
        self._merge_buffer: List[Tuple[str, DisplayText, Optional[Actions]]] = []
        self._merge_max_sentences = 3
        
        # æ¸è¿›å¼åˆå¹¶ç›¸å…³
        # ç”¨äºè¿½è¸ªå½“å‰å¯¹è¯çš„å¥å­æ•°ï¼Œå®ç° 1->2->3 æ¸è¿›å¼ç¼“å†²
        self._progressive_sentence_count = 0
        self._progressive_merge_enabled = True
        # å½“å‰è½®æ¬¡çš„æœ‰æ•ˆç¼“å†²å¤§å°ï¼ˆåœ¨æ–°ä¸€è½®å¼€å§‹æ—¶é”å®šï¼‰
        self._current_round_max = 1

    def _is_title_content(self, text: str) -> bool:
        """
        æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æ˜¯æ ‡é¢˜å†…å®¹ï¼ˆä»¥ # å¼€å¤´ï¼‰ã€‚
        """
        return text.strip().startswith('#')

    def _is_emotion_tag_only(self, text: str) -> bool:
        """
        æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä»…åŒ…å«æƒ…æ„Ÿæ ‡ç­¾ï¼ˆå¦‚ [neutral], [joy] ç­‰ï¼‰ã€‚
        è¿™äº›æ ‡ç­¾ä¸åº”è¯¥è¢«æœ—è¯»ã€‚
        """
        # ç§»é™¤æ‰€æœ‰æ–¹æ‹¬å·æ ‡ç­¾åæ£€æŸ¥æ˜¯å¦ä¸ºç©º
        cleaned = re.sub(r'\[\w+\]', '', text).strip()
        return len(cleaned) == 0 and '[' in text

    def _remove_emotion_tags(self, text: str) -> str:
        """
        ç§»é™¤æ–‡æœ¬ä¸­çš„æƒ…æ„Ÿæ ‡ç­¾ã€‚
        """
        return re.sub(r'\[\w+\]', '', text).strip()

    def _filter_title_lines(self, text: str) -> str:
        """
        è¿‡æ»¤æ–‡æœ¬ä¸­çš„ Markdown æ ‡é¢˜è¡Œï¼ˆ# å¼€å¤´çš„è¡Œï¼‰ã€‚
        
        Args:
            text: åŸå§‹æ–‡æœ¬
        
        Returns:
            str: è¿‡æ»¤åçš„æ–‡æœ¬
        """
        lines = text.split('\n')
        filtered_lines = [line for line in lines if not line.strip().startswith('#')]
        return '\n'.join(filtered_lines).strip()

    def _should_merge_audio(self, tts_engine: TTSInterface) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥å¯ç”¨éŸ³é¢‘åˆå¹¶åŠŸèƒ½ã€‚
        
        ä»…å½“åŒæ—¶æ»¡è¶³ä»¥ä¸‹æ¡ä»¶æ—¶å¯ç”¨ï¼š
        1. lingxi_settings.audio_merge_enabled = True
        2. å½“å‰ä½¿ç”¨çš„æ˜¯ Step TTS å¼•æ“
        
        Returns:
            bool: æ˜¯å¦å¯ç”¨éŸ³é¢‘åˆå¹¶
        """
        try:
            settings = get_lingxi_settings()
            audio_merge_enabled = settings.get("audio_merge_enabled", False)
            
            if not audio_merge_enabled:
                return False
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ Step TTS å¼•æ“
            engine_module = type(tts_engine).__module__
            is_step_tts = "step_tts" in engine_module
            
            if not is_step_tts:
                logger.debug(f"éŸ³é¢‘åˆå¹¶åŠŸèƒ½ä»…æ”¯æŒ Step TTSï¼Œå½“å‰å¼•æ“: {engine_module}")
                return False
            
            self._merge_max_sentences = settings.get("audio_merge_max_sentences", 3)
            self._progressive_merge_enabled = settings.get("progressive_merge_enabled", True)
            return True
            
        except Exception as e:
            logger.warning(f"æ£€æŸ¥éŸ³é¢‘åˆå¹¶è®¾ç½®æ—¶å‡ºé”™: {e}")
            return False

    async def speak(
        self,
        tts_text: str,
        display_text: DisplayText,
        actions: Optional[Actions],
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
    ) -> None:
        """
        Queue a TTS task while maintaining order of delivery.

        Args:
            tts_text: Text to synthesize
            display_text: Text to display in UI
            actions: Live2D model actions
            live2d_model: Live2D model instance
            tts_engine: TTS engine instance
            websocket_send: WebSocket send function
        """
        # ========== ç¬¬ä¸€æ­¥ï¼šæ ‡é¢˜è¿‡æ»¤ ==========
        # æ£€æŸ¥ TTS æ–‡æœ¬æˆ–æ˜¾ç¤ºæ–‡æœ¬æ˜¯å¦ä»¥ # å¼€å¤´ï¼ˆæ˜¯æ ‡é¢˜ï¼‰
        # æ³¨æ„ï¼šåŒæµæ¨¡å¼ä¸‹ tts_text æ¥è‡ª <say>ï¼Œdisplay_text.text æ¥è‡ª <show>
        display_text_str = display_text.text if isinstance(display_text, DisplayText) else str(display_text)
        
        if self._is_title_content(tts_text) or self._is_title_content(display_text_str):
            logger.info(f"ğŸš« è·³è¿‡æ ‡é¢˜å†…å®¹ï¼ˆä¸è¿›å…¥TTSï¼‰: tts='{tts_text[:50]}', display='{display_text_str[:50]}'")
            # æ ‡é¢˜åªæ˜¾ç¤ºï¼Œä¸ç”ŸæˆéŸ³é¢‘ï¼Œå‘é€é™éŸ³ payload
            await self._send_display_only(display_text, actions, websocket_send)
            return
        
        # ========== ç¬¬äºŒæ­¥ï¼šæƒ…æ„Ÿæ ‡ç­¾è¿‡æ»¤ ==========
        # æ£€æŸ¥æ˜¯å¦ä»…åŒ…å«æƒ…æ„Ÿæ ‡ç­¾ï¼ˆå¦‚ [neutral]ï¼‰
        if self._is_emotion_tag_only(tts_text):
            logger.info(f"ğŸš« è·³è¿‡çº¯æƒ…æ„Ÿæ ‡ç­¾ï¼ˆä¸è¿›å…¥TTSï¼‰: '{tts_text}'")
            # æƒ…æ„Ÿæ ‡ç­¾ä¸æ˜¾ç¤ºä¹Ÿä¸æœ—è¯»
            return
        
        # ç§»é™¤æ–‡æœ¬ä¸­çš„æƒ…æ„Ÿæ ‡ç­¾
        filtered_tts_text = self._remove_emotion_tags(tts_text)
        
        # è¿‡æ»¤æ–‡æœ¬ä¸­åµŒå…¥çš„æ ‡é¢˜è¡Œ
        filtered_tts_text = self._filter_title_lines(filtered_tts_text)
        
        # å¦‚æœè¿‡æ»¤åæ–‡æœ¬ä¸ºç©ºï¼Œåªæ˜¾ç¤ºä¸æœ—è¯»
        if not filtered_tts_text.strip():
            logger.debug(f"è¿‡æ»¤åæ–‡æœ¬ä¸ºç©ºï¼Œåªæ˜¾ç¤º: '{tts_text[:50]}...'")
            await self._send_display_only(display_text, actions, websocket_send)
            return
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ ‡ç‚¹ç¬¦å·
        if len(re.sub(r'[\s.,!?ï¼Œã€‚ï¼ï¼Ÿ\'"ã€ã€ï¼‰ã€‘\s]+', "", filtered_tts_text)) == 0:
            logger.debug("ç©ºTTSæ–‡æœ¬ï¼ˆçº¯æ ‡ç‚¹ï¼‰ï¼Œå‘é€é™éŸ³æ˜¾ç¤º")
            await self._send_display_only(display_text, actions, websocket_send)
            return

        # ========== ç¬¬äºŒæ­¥ï¼šTTS å¤„ç† ==========
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨éŸ³é¢‘åˆå¹¶
        should_merge = self._should_merge_audio(tts_engine)
        
        if should_merge:
            await self._speak_with_merge(
                filtered_tts_text, display_text, actions, live2d_model, tts_engine, websocket_send
            )
        else:
            await self._speak_single(
                filtered_tts_text, display_text, actions, live2d_model, tts_engine, websocket_send
            )

    async def _send_display_only(
        self,
        display_text: DisplayText,
        actions: Optional[Actions],
        websocket_send: WebSocketSend,
    ) -> None:
        """
        å‘é€ä»…æ˜¾ç¤ºçš„æ¶ˆæ¯ï¼ˆæ— éŸ³é¢‘ï¼‰ã€‚
        ç”¨äºæ ‡é¢˜ç­‰ä¸éœ€è¦æœ—è¯»çš„å†…å®¹ã€‚
        """
        current_sequence = self._sequence_counter
        self._sequence_counter += 1

        if not self._sender_task or self._sender_task.done():
            self._sender_task = asyncio.create_task(
                self._process_payload_queue(websocket_send)
            )

        await self._send_silent_payload(display_text, actions, current_sequence)

    async def _speak_with_merge(
        self,
        tts_text: str,
        display_text: DisplayText,
        actions: Optional[Actions],
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
    ) -> None:
        """
        ä½¿ç”¨éŸ³é¢‘åˆå¹¶æ¨¡å¼ï¼šç´¯ç§¯å¤šä¸ªå¥å­åä¸€èµ·ç”ŸæˆéŸ³é¢‘ï¼Œå‡å°‘ API è°ƒç”¨æ¬¡æ•°ã€‚
        
        æ¸è¿›å¼åˆå¹¶ï¼ˆprogressive_merge_enabled=Trueï¼‰ï¼š
        - ç¬¬1å¥ï¼šç«‹å³ç”ŸæˆéŸ³é¢‘ï¼ˆç¼“å†²å¤§å°=1ï¼‰
        - ç¬¬2-3å¥ï¼šç­‰å¾…2å¥ååˆå¹¶ç”Ÿæˆï¼ˆç¼“å†²å¤§å°=2ï¼‰
        - ç¬¬4å¥åŠä»¥åï¼šç­‰å¾…3å¥ååˆå¹¶ç”Ÿæˆï¼ˆç¼“å†²å¤§å°=3ï¼‰
        
        è¿™æ ·å¯ä»¥ç¡®ä¿é¦–å¥å¿«é€Ÿå“åº”ï¼ŒåŒæ—¶åç»­å¥å­ä»äº«å—åˆå¹¶ä¼˜åŒ–ã€‚
        
        é‡è¦ï¼šæ˜¾ç¤ºå’ŒéŸ³é¢‘æ˜¯åˆ†ç¦»çš„ï¼š
        - æ˜¾ç¤ºæ–‡æœ¬ä¿æŒåŸæ ·é€å¥æ˜¾ç¤º
        - éŸ³é¢‘åˆå¹¶åæŒ‰å­—æ•°æ¯”ä¾‹åˆ†é…æ’­æ”¾æ—¶é—´
        """
        # å¢åŠ å¥å­è®¡æ•°
        self._progressive_sentence_count += 1
        
        # å¦‚æœç¼“å†²åŒºä¸ºç©ºï¼Œè¯´æ˜æ˜¯æ–°ä¸€è½®åˆå¹¶çš„å¼€å§‹ï¼Œé”å®šè¿™ä¸€è½®çš„ effective_max
        if len(self._merge_buffer) == 0:
            if self._progressive_merge_enabled:
                # æ¸è¿›å¼ï¼šåŸºäºå½“å‰å¥å­æ•°è®¡ç®—è¿™ä¸€è½®çš„ç¼“å†²å¤§å°
                self._current_round_max = min(self._progressive_sentence_count, self._merge_max_sentences)
            else:
                self._current_round_max = self._merge_max_sentences
            logger.debug(f"ğŸ”„ æ–°ä¸€è½®åˆå¹¶å¼€å§‹ï¼Œæœ‰æ•ˆç¼“å†²å¤§å°: {self._current_round_max}")
        
        # å°†å½“å‰å¥å­åŠ å…¥ç¼“å†²åŒº
        self._merge_buffer.append((tts_text, display_text, actions))
        
        logger.info(f"ğŸ”— éŸ³é¢‘åˆå¹¶: ç¼“å†²åŒºç´¯ç§¯ {len(self._merge_buffer)}/{self._current_round_max} å¥ (æ¸è¿›={self._progressive_merge_enabled}, æ€»å¥æ•°={self._progressive_sentence_count})")
        
        # å¦‚æœç¼“å†²åŒºè¾¾åˆ°è¿™ä¸€è½®çš„æœ‰æ•ˆæœ€å¤§å¥å­æ•°ï¼Œæ‰§è¡Œåˆå¹¶ç”Ÿæˆ
        if len(self._merge_buffer) >= self._current_round_max:
            if self._current_round_max == 1:
                logger.info(f"âš¡ æ¸è¿›å¼åˆå¹¶: é¦–å¥ç«‹å³å“åº”")
            elif self._current_round_max < self._merge_max_sentences:
                logger.info(f"ğŸ”— æ¸è¿›å¼åˆå¹¶: ç¼“å†² {self._current_round_max} å¥åç”Ÿæˆ")
            else:
                logger.info(f"ğŸ”— éŸ³é¢‘åˆå¹¶: è¾¾åˆ°æœ€å¤§å¥å­æ•°ï¼Œå¼€å§‹åˆå¹¶ç”Ÿæˆ")
            await self._flush_merge_buffer(live2d_model, tts_engine, websocket_send)

    def reset_for_new_conversation(self) -> None:
        """
        ä¸ºæ–°ä¸€è½®å¯¹è¯é‡ç½®çŠ¶æ€ã€‚
        åº”åœ¨ç”¨æˆ·å‘é€æ–°æ¶ˆæ¯æ—¶è°ƒç”¨ï¼Œä»¥ä¾¿æ¸è¿›å¼åˆå¹¶ä»1å¼€å§‹ã€‚
        """
        self._progressive_sentence_count = 0
        logger.debug("ğŸ”„ TTS ç®¡ç†å™¨å·²é‡ç½®ï¼Œæ¸è¿›å¼åˆå¹¶å°†ä»é¦–å¥ç«‹å³å“åº”å¼€å§‹")

    async def flush_remaining(
        self,
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
    ) -> None:
        """
        åˆ·æ–°åˆå¹¶ç¼“å†²åŒºä¸­å‰©ä½™çš„å†…å®¹ã€‚
        åº”åœ¨å¯¹è¯ç»“æŸæ—¶è°ƒç”¨ã€‚
        """
        if self._merge_buffer:
            await self._flush_merge_buffer(live2d_model, tts_engine, websocket_send)

    async def _flush_merge_buffer(
        self,
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
    ) -> None:
        """
        å°†ç¼“å†²åŒºä¸­çš„å¥å­åˆå¹¶åç”ŸæˆéŸ³é¢‘ã€‚
        
        å…³é”®ï¼šæ˜¾ç¤ºå’ŒéŸ³é¢‘åˆ†ç¦»å¤„ç†
        - æ¯å¥è¯ä¿æŒç‹¬ç«‹æ˜¾ç¤ºï¼ˆä¿æŒåŸæ ·å¼ï¼‰
        - éŸ³é¢‘åˆå¹¶ä¸ºä¸€ä¸ªï¼Œç„¶åæŒ‰å­—æ•°æ¯”ä¾‹åˆ†é…æ’­æ”¾æ—¶é—´
        """
        if not self._merge_buffer:
            return
        
        buffer_copy = self._merge_buffer.copy()
        self._merge_buffer.clear()
        
        # åˆå¹¶ TTS æ–‡æœ¬
        merged_tts_text = "".join([item[0] for item in buffer_copy])
        
        # è®¡ç®—æ¯ä¸ªå¥å­çš„å­—æ•°
        char_counts = [len(item[0]) for item in buffer_copy]
        total_chars = sum(char_counts)
        
        logger.info(f"ğŸ”— éŸ³é¢‘åˆå¹¶: åˆå¹¶ {len(buffer_copy)} ä¸ªå¥å­, æ€»å­—æ•°: {total_chars}")
        
        # Step TTS ä¸²è¡Œç”Ÿæˆåˆå¹¶éŸ³é¢‘
        audio_file_path = None
        total_duration_ms = 0
        
        try:
            audio_file_path = await tts_engine.async_generate_audio(
                text=merged_tts_text,
                file_name_no_ext=f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{str(uuid.uuid4())[:8]}",
            )
            
            # è·å–éŸ³é¢‘æ€»æ—¶é•¿
            total_duration_ms = get_audio_duration(audio_file_path)
            logger.info(f"ğŸ”— åˆå¹¶éŸ³é¢‘ç”Ÿæˆå®Œæˆ, æ—¶é•¿: {total_duration_ms}ms")
            
        except Exception as e:
            logger.error(f"åˆå¹¶éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            # å¤±è´¥æ—¶å‘é€é™éŸ³ payloads
            for tts_text, display_text, actions in buffer_copy:
                await self._send_display_only(display_text, actions, websocket_send)
            return
        
        try:
            # è¯»å–éŸ³é¢‘æ•°æ®
            from pydub import AudioSegment
            audio = AudioSegment.from_file(audio_file_path)
            audio_bytes = audio.export(format="wav").read()
            import base64
            audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
            
            # è®¡ç®—éŸ³é‡æ•°æ®
            from ..utils.stream_audio import _get_volume_by_chunks
            chunk_length_ms = 20
            volumes = _get_volume_by_chunks(audio, chunk_length_ms)
            
            # æŒ‰å­—æ•°æ¯”ä¾‹åˆ†é…æ¯å¥è¯çš„æ’­æ”¾æ—¶é—´
            current_time_offset = 0
            
            for i, (tts_text, display_text, actions) in enumerate(buffer_copy):
                # è®¡ç®—è¿™å¥è¯çš„æ—¶é•¿æ¯”ä¾‹
                char_ratio = char_counts[i] / total_chars if total_chars > 0 else 1.0 / len(buffer_copy)
                sentence_duration_ms = int(total_duration_ms * char_ratio)
                
                # è®¡ç®—è¿™å¥è¯å¯¹åº”çš„éŸ³é‡åˆ‡ç‰‡
                start_volume_idx = int(current_time_offset / chunk_length_ms)
                end_volume_idx = int((current_time_offset + sentence_duration_ms) / chunk_length_ms)
                sentence_volumes = volumes[start_volume_idx:end_volume_idx] if start_volume_idx < len(volumes) else []
                
                logger.debug(f"ğŸ”— å¥å­ {i+1}: '{tts_text[:20]}...' æ—¶é•¿={sentence_duration_ms}ms, å­—æ•°æ¯”ä¾‹={char_ratio:.2f}")
                
                # æ„å»ºè¿™å¥è¯çš„ payload
                # ç¬¬ä¸€å¥æºå¸¦å®Œæ•´éŸ³é¢‘ï¼Œåç»­å¥å­åªæºå¸¦æ˜¾ç¤ºä¿¡æ¯å’Œé¢„è®¡æŒç»­æ—¶é—´
                if i == 0:
                    # ç¬¬ä¸€å¥ï¼šæºå¸¦å®Œæ•´éŸ³é¢‘
                    payload = {
                        "type": "audio",
                        "audio": audio_base64,
                        "volumes": volumes,  # å®Œæ•´éŸ³é‡æ•°æ®
                        "slice_length": chunk_length_ms,
                        "display_text": display_text.to_dict() if isinstance(display_text, DisplayText) else display_text,
                        "actions": actions.to_dict() if actions else None,
                        "forwarded": False,
                        # é¢å¤–ä¿¡æ¯ï¼šç”¨äºå‰ç«¯åˆ†æ®µæ˜¾ç¤º
                        "merge_info": {
                            "is_merged": True,
                            "total_sentences": len(buffer_copy),
                            "sentence_index": i,
                            "sentence_duration_ms": sentence_duration_ms,
                            "total_duration_ms": total_duration_ms,
                        }
                    }
                else:
                    # åç»­å¥å­ï¼šä¸æºå¸¦éŸ³é¢‘ï¼Œåªæºå¸¦æ˜¾ç¤ºä¿¡æ¯å’Œè®¡æ—¶ä¿¡æ¯
                    payload = {
                        "type": "audio",
                        "audio": None,  # æ— éŸ³é¢‘
                        "volumes": sentence_volumes,  # éƒ¨åˆ†éŸ³é‡æ•°æ®ç”¨äºå£å‹åŒæ­¥
                        "slice_length": chunk_length_ms,
                        "display_text": display_text.to_dict() if isinstance(display_text, DisplayText) else display_text,
                        "actions": actions.to_dict() if actions else None,
                        "forwarded": False,
                        "merge_info": {
                            "is_merged": True,
                            "total_sentences": len(buffer_copy),
                            "sentence_index": i,
                            "sentence_duration_ms": sentence_duration_ms,
                            "delay_before_show_ms": current_time_offset,  # æ˜¾ç¤ºå‰å»¶è¿Ÿ
                            "total_duration_ms": total_duration_ms,
                        }
                    }
                
                await websocket_send(json.dumps(payload))
                current_time_offset += sentence_duration_ms
                
        except Exception as e:
            logger.error(f"å¤„ç†åˆå¹¶éŸ³é¢‘ payload å¤±è´¥: {e}")
            # å¤±è´¥æ—¶å‘é€é™éŸ³ payloads
            for tts_text, display_text, actions in buffer_copy:
                await self._send_display_only(display_text, actions, websocket_send)
        finally:
            if audio_file_path:
                tts_engine.remove_file(audio_file_path)
                logger.debug("åˆå¹¶éŸ³é¢‘ç¼“å­˜æ–‡ä»¶å·²æ¸…ç†")

    async def _speak_serial(
        self,
        tts_text: str,
        display_text: DisplayText,
        actions: Optional[Actions],
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
    ) -> None:
        """
        ä¸²è¡Œ TTS æ¨¡å¼ï¼šç›´æ¥æ‰§è¡Œ TTS å¹¶ç­‰å¾…å®Œæˆï¼Œä¸åˆ›å»ºå¹¶å‘ä»»åŠ¡ã€‚
        ç”¨äº Step TTS ç­‰ä¸æ”¯æŒå¹¶å‘çš„å¼•æ“ã€‚
        """
        logger.debug(
            f"ğŸƒ ä¸²è¡Œ TTS ç”Ÿæˆ: '''{tts_text[:50]}...''' (by {display_text.name})"
        )
        
        audio_file_path = None
        try:
            # ç›´æ¥ç”ŸæˆéŸ³é¢‘ï¼ˆä¸åˆ›å»ºå¹¶å‘ä»»åŠ¡ï¼‰
            audio_file_path = await tts_engine.async_generate_audio(
                text=tts_text,
                file_name_no_ext=f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{str(uuid.uuid4())[:8]}",
            )
            
            # å‡†å¤‡å¹¶å‘é€ payload
            payload = prepare_audio_payload(
                audio_path=audio_file_path,
                display_text=display_text,
                actions=actions,
            )
            await websocket_send(json.dumps(payload))
            
        except Exception as e:
            logger.error(f"ä¸²è¡Œ TTS ç”Ÿæˆå¤±è´¥: {e}")
            # å‘é€é™éŸ³ payload
            payload = prepare_audio_payload(
                audio_path=None,
                display_text=display_text,
                actions=actions,
            )
            await websocket_send(json.dumps(payload))
        finally:
            if audio_file_path:
                tts_engine.remove_file(audio_file_path)
                logger.debug("éŸ³é¢‘ç¼“å­˜æ–‡ä»¶å·²æ¸…ç†")

    async def _speak_single(
        self,
        tts_text: str,
        display_text: DisplayText,
        actions: Optional[Actions],
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        websocket_send: WebSocketSend,
    ) -> None:
        """
        å•å¥ TTS æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰ã€‚
        """
        logger.debug(
            f"ğŸƒQueuing TTS task for: '''{tts_text}''' (by {display_text.name})"
        )

        # Get current sequence number
        current_sequence = self._sequence_counter
        self._sequence_counter += 1

        # Start sender task if not running
        if not self._sender_task or self._sender_task.done():
            self._sender_task = asyncio.create_task(
                self._process_payload_queue(websocket_send)
            )

        # Create and queue the TTS task
        task = asyncio.create_task(
            self._process_tts(
                tts_text=tts_text,
                display_text=display_text,
                actions=actions,
                live2d_model=live2d_model,
                tts_engine=tts_engine,
                sequence_number=current_sequence,
            )
        )
        self.task_list.append(task)

    async def _process_payload_queue(self, websocket_send: WebSocketSend) -> None:
        """
        Process and send payloads in correct order.
        Runs continuously until all payloads are processed.
        """
        buffered_payloads: Dict[int, Dict] = {}

        while True:
            try:
                # Get payload from queue
                payload, sequence_number = await self._payload_queue.get()
                buffered_payloads[sequence_number] = payload

                # Send payloads in order
                while self._next_sequence_to_send in buffered_payloads:
                    next_payload = buffered_payloads.pop(self._next_sequence_to_send)
                    await websocket_send(json.dumps(next_payload))
                    self._next_sequence_to_send += 1

                self._payload_queue.task_done()

            except asyncio.CancelledError:
                break

    async def _send_silent_payload(
        self,
        display_text: DisplayText,
        actions: Optional[Actions],
        sequence_number: int,
    ) -> None:
        """Queue a silent audio payload"""
        audio_payload = prepare_audio_payload(
            audio_path=None,
            display_text=display_text,
            actions=actions,
        )
        await self._payload_queue.put((audio_payload, sequence_number))

    async def _process_tts(
        self,
        tts_text: str,
        display_text: DisplayText,
        actions: Optional[Actions],
        live2d_model: Live2dModel,
        tts_engine: TTSInterface,
        sequence_number: int,
    ) -> None:
        """Process TTS generation and queue the result for ordered delivery"""
        audio_file_path = None
        try:
            audio_file_path = await self._generate_audio(tts_engine, tts_text)
            payload = prepare_audio_payload(
                audio_path=audio_file_path,
                display_text=display_text,
                actions=actions,
            )
            # Queue the payload with its sequence number
            await self._payload_queue.put((payload, sequence_number))

        except Exception as e:
            logger.error(f"Error preparing audio payload: {e}")
            # Queue silent payload for error case
            payload = prepare_audio_payload(
                audio_path=None,
                display_text=display_text,
                actions=actions,
            )
            await self._payload_queue.put((payload, sequence_number))

        finally:
            if audio_file_path:
                tts_engine.remove_file(audio_file_path)
                logger.debug("Audio cache file cleaned.")

    async def _generate_audio(self, tts_engine: TTSInterface, text: str) -> str:
        """Generate audio file from text"""
        logger.debug(f"ğŸƒGenerating audio for '''{text}'''...")
        return await tts_engine.async_generate_audio(
            text=text,
            file_name_no_ext=f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{str(uuid.uuid4())[:8]}",
        )

    def clear(self) -> None:
        """Clear all pending tasks and reset state"""
        self.task_list.clear()
        if self._sender_task:
            self._sender_task.cancel()
        self._sequence_counter = 0
        self._next_sequence_to_send = 0
        # Create a new queue to clear any pending items
        self._payload_queue = asyncio.Queue()
        # æ¸…ç©ºåˆå¹¶ç¼“å†²åŒº
        self._merge_buffer.clear()
