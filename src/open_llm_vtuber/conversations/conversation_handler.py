import asyncio
import json
from typing import Dict, Optional, Callable

import numpy as np
from fastapi import WebSocket
from loguru import logger

from ..chat_group import ChatGroupManager
from ..chat_history_manager import store_message
from ..service_context import ServiceContext
from .group_conversation import process_group_conversation
from .single_conversation import process_single_conversation
from .conversation_utils import EMOJI_LIST
from .types import GroupConversationState
from prompts import prompt_loader


async def handle_conversation_trigger(
    msg_type: str,
    data: dict,
    client_uid: str,
    context: ServiceContext,
    websocket: WebSocket,
    client_contexts: Dict[str, ServiceContext],
    client_connections: Dict[str, WebSocket],
    chat_group_manager: ChatGroupManager,
    received_data_buffers: Dict[str, np.ndarray],
    current_conversation_tasks: Dict[str, Optional[asyncio.Task]],
    broadcast_to_group: Callable,
) -> None:
    """Handle triggers that start a conversation"""
    metadata = None

    if msg_type == "ai-speak-signal":
        try:
            # Get proactive speak prompt from config
            prompt_name = "proactive_speak_prompt"
            prompt_file = context.system_config.tool_prompts.get(prompt_name)
            if prompt_file:
                user_input = prompt_loader.load_util(prompt_file)
            else:
                logger.warning("Proactive speak prompt not configured, using default")
                user_input = "Please say something."
        except Exception as e:
            logger.error(f"Error loading proactive speak prompt: {e}")
            user_input = "Please say something."

        # Add metadata to indicate this is a proactive speak request
        # that should be skipped in both memory and history
        metadata = {
            "proactive_speak": True,
            "skip_memory": True,  # Skip storing in AI's internal memory
            "skip_history": True,  # Skip storing in local conversation history
        }

        await websocket.send_text(
            json.dumps(
                {
                    "type": "full-text",
                    "text": "AI wants to speak something...",
                }
            )
        )
    elif msg_type == "text-input":
        user_input = data.get("text", "")
    else:  # mic-audio-end
        user_input = received_data_buffers[client_uid]
        received_data_buffers[client_uid] = np.array([])

    # èŽ·å–å”¤é†’è¯é…ç½®ï¼ˆä»…è¯­éŸ³è¾“å…¥æ—¶æœ‰æ•ˆï¼‰
    wake_word_config = data.get("wake_word_config", None)
    if wake_word_config:
        logger.info(f"Wake word config: enabled={wake_word_config.get('enabled')}, words={wake_word_config.get('words')}")

    # èŽ·å–åœæ­¢è¯é…ç½®ï¼ˆä»…è¯­éŸ³è¾“å…¥æ—¶æœ‰æ•ˆï¼Œç”¨äºŽè¯­éŸ³æ‰“æ–­ï¼‰
    stop_word_config = data.get("stop_word_config", None)
    if stop_word_config:
        logger.info(f"Stop word config: enabled={stop_word_config.get('enabled')}, words={stop_word_config.get('words')}")

    # åœæ­¢è¯æ—©æœŸæ£€æµ‹ï¼šå¦‚æžœæ˜¯è¯­éŸ³è¾“å…¥ä¸”å¯ç”¨äº†åœæ­¢è¯ï¼Œå…ˆè¿›è¡Œ ASR æ£€æµ‹
    # å¦‚æžœæ£€æµ‹åˆ°åœæ­¢è¯ï¼Œç›´æŽ¥è§¦å‘æ‰“æ–­è€Œä¸æ˜¯å¯åŠ¨æ–°å¯¹è¯
    pre_transcribed_text = None  # é¢„è½¬å½•çš„æ–‡æœ¬ï¼Œé¿å… single_conversation é‡å¤ ASR
    if msg_type == "mic-audio-end" and stop_word_config and stop_word_config.get("enabled", False):
        stop_words = stop_word_config.get("words", [])
        fuzzy_pinyin = stop_word_config.get("fuzzy_pinyin", False)
        
        if stop_words and isinstance(user_input, np.ndarray) and len(user_input) > 0:
            # å…ˆè¿›è¡Œè¯­éŸ³è¯†åˆ«
            try:
                transcribed_text = await context.asr_engine.async_transcribe_np(user_input)
                if transcribed_text:
                    transcribed_text = transcribed_text.strip()
                    pre_transcribed_text = transcribed_text  # ä¿å­˜ç»“æžœä¾›åŽç»­ä½¿ç”¨
                    logger.info(f"Stop word early check - ASR result: '{transcribed_text}'")
                    
                    # æ£€æµ‹åœæ­¢è¯
                    from .conversation_utils import check_stop_word
                    result = check_stop_word(transcribed_text, stop_words, fuzzy_pinyin)
                    
                    if result["has_stop_word"]:
                        matched_word = result["matched_word"]
                        logger.info(f"ðŸ›‘ Stop word '{matched_word}' detected early, triggering interrupt instead of new conversation")
                        
                        # æ¸…ç©ºéŸ³é¢‘æŽ¥æ”¶ç¼“å†²åŒº
                        if client_uid in received_data_buffers:
                            received_data_buffers[client_uid] = np.array([])
                            logger.info(f"ðŸ§¹ Cleared audio buffer for client {client_uid}")
                        
                        # å‘é€è¯†åˆ«ç»“æžœç»™å‰ç«¯ï¼ˆæ ‡è®°ä¸ºåœæ­¢è¯ï¼‰
                        await websocket.send_text(
                            json.dumps({
                                "type": "user-input-transcription",
                                "text": f"ï¼ˆåœæ­¢è¯ï¼š{matched_word}ï¼‰",
                                "original_text": transcribed_text,
                                "is_stop_word": True
                            })
                        )
                        
                        # ç›´æŽ¥è§¦å‘æ‰“æ–­å¤„ç†ï¼ˆå–æ¶ˆå½“å‰æ­£åœ¨è¿›è¡Œçš„å¯¹è¯ä»»åŠ¡ï¼‰
                        await handle_individual_interrupt(
                            client_uid=client_uid,
                            current_conversation_tasks=current_conversation_tasks,
                            context=context,
                            heard_response="",  # è¢«æ‰“æ–­çš„å“åº”ï¼Œè¿™é‡Œä¸ºç©º
                        )
                        
                        # å‘é€æ‰“æ–­æŽ§åˆ¶ä¿¡å·ç»™å‰ç«¯
                        await websocket.send_text(
                            json.dumps({"type": "control", "text": "interrupt"})
                        )
                        
                        # ä¸å¯åŠ¨æ–°å¯¹è¯ï¼Œç›´æŽ¥è¿”å›ž
                        return
            except Exception as e:
                logger.error(f"Stop word early check failed: {e}")
                # å¤±è´¥æ—¶ç»§ç»­æ­£å¸¸æµç¨‹

    # å¤„ç†å›¾ç‰‡æ•°æ®ï¼šå°†å‰ç«¯å‘é€çš„ base64 å­—ç¬¦ä¸²æ•°ç»„è½¬æ¢ä¸ºåŽç«¯æœŸæœ›çš„æ ¼å¼
    raw_images = data.get("images")
    images = None
    if raw_images:
        images = []
        for img in raw_images:
            if isinstance(img, str):
                # å‰ç«¯å‘é€çš„æ˜¯ base64 data URL å­—ç¬¦ä¸²
                # éœ€è¦è½¬æ¢ä¸º {"source": "upload", "data": ..., "mime_type": ...} æ ¼å¼
                mime_type = "image/png"  # é»˜è®¤
                if img.startswith("data:"):
                    # è§£æž data URL èŽ·å– MIME ç±»åž‹
                    # æ ¼å¼: data:image/png;base64,xxxxx
                    try:
                        header = img.split(",")[0]
                        if ":" in header and ";" in header:
                            mime_type = header.split(":")[1].split(";")[0]
                    except Exception:
                        pass
                images.append({
                    "source": "upload",
                    "data": img,
                    "mime_type": mime_type
                })
            elif isinstance(img, dict):
                # å·²ç»æ˜¯æ­£ç¡®çš„æ ¼å¼
                images.append(img)
        
        if images:
            logger.info(f"Received {len(images)} images from client")
    
    session_emoji = np.random.choice(EMOJI_LIST)

    group = chat_group_manager.get_client_group(client_uid)
    if group and len(group.members) > 1:
        # Use group_id as task key for group conversations
        task_key = group.group_id
        if (
            task_key not in current_conversation_tasks
            or current_conversation_tasks[task_key].done()
        ):
            logger.info(f"Starting new group conversation for {task_key}")

            current_conversation_tasks[task_key] = asyncio.create_task(
                process_group_conversation(
                    client_contexts=client_contexts,
                    client_connections=client_connections,
                    broadcast_func=broadcast_to_group,
                    group_members=group.members,
                    initiator_client_uid=client_uid,
                    user_input=user_input,
                    images=images,
                    session_emoji=session_emoji,
                    metadata=metadata,
                )
            )
    else:
        # Use client_uid as task key for individual conversations
        current_conversation_tasks[client_uid] = asyncio.create_task(
            process_single_conversation(
                context=context,
                websocket_send=websocket.send_text,
                client_uid=client_uid,
                user_input=user_input,
                images=images,
                session_emoji=session_emoji,
                metadata=metadata,
                wake_word_config=wake_word_config,
                stop_word_config=stop_word_config,
                pre_transcribed_text=pre_transcribed_text,  # é¢„è½¬å½•æ–‡æœ¬ï¼Œé¿å…é‡å¤ ASR
            )
        )


async def handle_individual_interrupt(
    client_uid: str,
    current_conversation_tasks: Dict[str, Optional[asyncio.Task]],
    context: ServiceContext,
    heard_response: str,
):
    """å¤„ç†å•ç”¨æˆ·å¯¹è¯æ‰“æ–­
    
    æ‰§è¡Œä»¥ä¸‹æ¸…ç†æ“ä½œï¼š
    1. å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„å¯¹è¯ä»»åŠ¡ï¼ˆåœæ­¢ LLM ç”Ÿæˆå’Œ TTS åˆæˆï¼‰
    2. é€šçŸ¥ agent_engine å¤„ç†æ‰“æ–­ï¼ˆæ›´æ–°å†…å­˜/åŽ†å²ï¼‰
    3. é‡ç½® agent_engine çš„æ‰“æ–­æ ‡å¿—
    4. è®°å½•æ‰“æ–­åˆ°åŽ†å²
    """
    logger.info(f"ðŸ›‘ Processing interrupt for client {client_uid}")
    
    if client_uid in current_conversation_tasks:
        task = current_conversation_tasks[client_uid]
        if task and not task.done():
            # å–æ¶ˆä»»åŠ¡ä¼šè§¦å‘ CancelledErrorï¼Œç»ˆæ­¢æ‰€æœ‰æ­£åœ¨è¿›è¡Œçš„å¼‚æ­¥æ“ä½œ
            task.cancel()
            # ç­‰å¾…ä»»åŠ¡çœŸæ­£è¢«å–æ¶ˆ
            try:
                await asyncio.wait_for(asyncio.shield(task), timeout=0.5)
            except (asyncio.CancelledError, asyncio.TimeoutError):
                pass
            logger.info("ðŸ›‘ Conversation task was successfully interrupted")
        
        # æ¸…é™¤ä»»åŠ¡å¼•ç”¨
        current_conversation_tasks[client_uid] = None

    # é€šçŸ¥ agent_engine å¤„ç†æ‰“æ–­
    try:
        context.agent_engine.handle_interrupt(heard_response)
        # é‡ç½®æ‰“æ–­æ ‡å¿—ï¼Œä¸ºä¸‹ä¸€æ¬¡å¯¹è¯åšå‡†å¤‡
        if hasattr(context.agent_engine, 'reset_interrupt'):
            context.agent_engine.reset_interrupt()
            logger.debug("Agent interrupt flag reset")
    except Exception as e:
        logger.error(f"Error handling interrupt: {e}")

    # è®°å½•æ‰“æ–­åˆ°åŽ†å²
    if context.history_uid and heard_response:
        store_message(
            conf_uid=context.character_config.conf_uid,
            history_uid=context.history_uid,
            role="ai",
            content=heard_response,
            name=context.character_config.character_name,
            avatar=context.character_config.avatar,
        )
        store_message(
            conf_uid=context.character_config.conf_uid,
            history_uid=context.history_uid,
            role="system",
            content="[Interrupted by user]",
        )
    
    logger.info(f"âœ… Interrupt handling complete for client {client_uid}")


async def handle_group_interrupt(
    group_id: str,
    heard_response: str,
    current_conversation_tasks: Dict[str, Optional[asyncio.Task]],
    chat_group_manager: ChatGroupManager,
    client_contexts: Dict[str, ServiceContext],
    broadcast_to_group: Callable,
) -> None:
    """Handles interruption for a group conversation"""
    task = current_conversation_tasks.get(group_id)
    if not task or task.done():
        return

    # Get state and speaker info before cancellation
    state = GroupConversationState.get_state(group_id)
    current_speaker_uid = state.current_speaker_uid if state else None

    # Get context from current speaker
    context = None
    group = chat_group_manager.get_group_by_id(group_id)
    if current_speaker_uid:
        context = client_contexts.get(current_speaker_uid)
        logger.info(f"Found current speaker context for {current_speaker_uid}")
    if not context and group and group.members:
        logger.warning(f"No context found for group {group_id}, using first member")
        context = client_contexts.get(next(iter(group.members)))

    # Now cancel the task
    task.cancel()
    try:
        await task
    except asyncio.CancelledError:
        logger.info(f"ðŸ›‘ Group conversation {group_id} cancelled successfully.")

    current_conversation_tasks.pop(group_id, None)
    GroupConversationState.remove_state(group_id)  # Clean up state after we've used it

    # Store messages with speaker info
    if context and group:
        for member_uid in group.members:
            if member_uid in client_contexts:
                try:
                    member_ctx = client_contexts[member_uid]
                    member_ctx.agent_engine.handle_interrupt(heard_response)
                    store_message(
                        conf_uid=member_ctx.character_config.conf_uid,
                        history_uid=member_ctx.history_uid,
                        role="ai",
                        content=heard_response,
                        name=context.character_config.character_name,
                        avatar=context.character_config.avatar,
                    )
                    store_message(
                        conf_uid=member_ctx.character_config.conf_uid,
                        history_uid=member_ctx.history_uid,
                        role="system",
                        content="[Interrupted by user]",
                    )
                except Exception as e:
                    logger.error(f"Error handling interrupt for {member_uid}: {e}")

    await broadcast_to_group(
        list(group.members),
        {
            "type": "interrupt-signal",
            "text": "conversation-interrupted",
        },
    )
